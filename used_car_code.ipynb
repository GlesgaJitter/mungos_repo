{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3fc9b05",
   "metadata": {},
   "source": [
    "# Section 1: Business understanding\n",
    "\n",
    "We study used-car data to study the used-car market in the UK, and look to uderstand what determins the price of a used car. \n",
    "\n",
    "Question 1: Which individual features of a used car has the greatest affect on its price?\n",
    "\n",
    "Question 2: Is it possible to predict the price of a used car based on existing data?\n",
    "\n",
    "Question 3: Which 3 features of a used car are the best predictor of its price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d887cf3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# import packages for data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "# import glob to load .csv data files\n",
    "import glob\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e1a1ac",
   "metadata": {},
   "source": [
    "# Section 2: Data Understanding\n",
    "\n",
    "Gather, clean, and assemble data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c5abf8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## Create DataFrame by concatenating necessary used car data files\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_data\u001b[39m():\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*.csv\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "## Create DataFrame by concatenating 'make' used car data files\n",
    "\n",
    "def get_data():\n",
    "    \n",
    "    \"\"\"\n",
    "    Collects and assembles a dataframe from stored data files. This function:    \n",
    "    1. Calls in all .csv files stored in the local folder and creates a temp DataFrame 'pulled'\n",
    "    2. Ignores 'unclean', 'cclass', and 'focus' columns\n",
    "    3. A 'make' column created from the file name is appened to 'pulled'\n",
    "    4. Tax columns headers are updated to be a consistent name\n",
    "    5. 'pulled' is appended to df, the collated DataFrame\n",
    "    \n",
    "    inputs:\n",
    "    None\n",
    "    \n",
    "    returns:\n",
    "    df: DataFrame of assembled data\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for file_name in glob.glob('*.csv'):\n",
    "\n",
    "        # cclass.csv and focus.csv contain subsets of merc.csv and ford.csv, respectively. \n",
    "        # These files, along with their uncleaned versions, are not included to avoid duplication. \n",
    "        if 'unclean' not in file_name and 'cclass' not in file_name and 'focus' not in file_name:\n",
    "            pulled = pd.read_csv(file_name, low_memory=False)\n",
    "            \n",
    "             # create 'make' column by dropping '.csv' part of file_name\n",
    "            pulled['make'] = file_name[:-4]\n",
    "\n",
    "            # tax is given as 'tax' in some files and 'tax(£)' in others. \n",
    "            # We rename all columns to 'tax' for consistency. \n",
    "            try:\n",
    "                pulled.rename(columns = {'tax(£)':'tax'}, inplace = True)\n",
    "            except:\n",
    "                continue\n",
    "            df = pd.concat([df,pulled],axis=0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = get_data()\n",
    "df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc82ba9",
   "metadata": {},
   "source": [
    "#  Section 3: Data Preparation\n",
    "\n",
    "Cleaning data by recasting 'year' feature to new 'age' feature, to aid interpretation of results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d57c460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recast year column as 'age' to make interpretation easier, and drop 'year' column. \n",
    "\n",
    "df['age'] = 2020 - df['year']\n",
    "df.drop(['year'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581bc8e7",
   "metadata": {},
   "source": [
    "Create dummy columns for catagorical features (car model, transmission type, fuel type). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcafdb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract catagorical columns to be recast a dummy columns\n",
    "\n",
    "cat_df = df.select_dtypes(include=['object']).copy()\n",
    "cat_cols = cat_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0483690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create numerical-only dataframe by adding dummy columns for categorical data. \n",
    "\n",
    "def create_dummy_df(df, cat_cols):\n",
    "    \n",
    "    \"\"\"\n",
    "    Converts catagorical columns to dummy columns. This function:\n",
    "    1. Loops over each column name in cat_cols\n",
    "    2. For each column, dummy columns are created\n",
    "    3. New dummy columns are appended\n",
    "    4. Original catagorical column is dropped\n",
    "    \n",
    "    Inputs:\n",
    "    df: used-car data set\n",
    "    cat_cols: list of catagorical columns headers\n",
    "    \n",
    "    Returns:\n",
    "    df: DataFrame with dummy columns\n",
    "    \"\"\"\n",
    "\n",
    "    for col in cat_cols:\n",
    "        try:\n",
    "            df = pd.concat([df.drop(col, axis=1), pd.get_dummies(df[col], prefix=col, prefix_sep='_', drop_first=True)], axis=1)\n",
    "        except:\n",
    "            continue\n",
    "    return df.astype(np.float)\n",
    "\n",
    "dum_df = create_dummy_df(df, cat_cols)\n",
    "dum_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7add8f4",
   "metadata": {},
   "source": [
    "Rows:Columns still comfortably accommodates 10:1 requirement, so we are able to continue using all catagorical dummy columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab51b83",
   "metadata": {},
   "source": [
    "# Section 4: Modelling\n",
    "\n",
    "We train and test a linear regression model to predict used-car price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dabd4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelling using all features is computationally time-consuming \n",
    "# We facilitate adding and removing features to speed up model training\n",
    "\n",
    "# These lists contain groups of features to aid investigation\n",
    "# Lists of makes, models, transmission, and fuel created by string-matching columns in dum_df\n",
    "model_list = [col for col in dum_df.columns if 'model' in col]\n",
    "make_list  = [col for col in dum_df.columns if 'make' in col]\n",
    "trans_list = [col for col in dum_df.columns if 'transmission' in col]\n",
    "fuel_list  = [col for col in dum_df.columns if 'fuelType' in col]\n",
    "mil_list = ['mileage']\n",
    "tax_list = ['tax']\n",
    "mpg_list = ['mpg']\n",
    "eng_list = ['engineSize']\n",
    "age_list = ['age']\n",
    "\n",
    "\n",
    "# subset features to train linear regression model\n",
    "# users should remove from this list features which are not to be used for training\n",
    "\n",
    "feat_list = [mil_list, eng_list, age_list, tax_list, mpg_list, make_list, model_list, trans_list, fuel_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e56b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns a concise string for the user-chosen features used in the model training. \n",
    "\n",
    "def get_feat_output(feature_list):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function creates a string describing the features included to aid investigation:\n",
    "    1. feature_list is checked for appropriate strings\n",
    "    2. A string 'output_list' is built and returned\n",
    "    \n",
    "    Inputs:\n",
    "    feature_list: list of features used for analysis\n",
    "    \n",
    "    Returns:\n",
    "    output_list: description string\n",
    "    \"\"\"\n",
    "    \n",
    "    output_list = ''\n",
    "    if 'mileage' in feature_list:\n",
    "        output_list += 'miles_'\n",
    "    if 'tax' in feature_list:\n",
    "        output_list += 'tax_'\n",
    "    if 'mpg' in feature_list:\n",
    "        output_list += 'mpg_'\n",
    "    if 'engineSize' in feature_list:\n",
    "        output_list += 'eng_'\n",
    "    if 'age' in feature_list:\n",
    "        output_list += 'age_'\n",
    "    if 'make_bmw' in feature_list:\n",
    "        output_list += 'make_'\n",
    "    if 'model_ 2 Series' in feature_list:\n",
    "        output_list += 'model_'\n",
    "    if 'transmission_Manual' in feature_list:\n",
    "        output_list += 'trans_'\n",
    "    if 'fuelType_Electric' in feature_list:\n",
    "        output_list += 'fuel_'\n",
    "        \n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0069fb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over combinations of above lists - \n",
    "\n",
    "# User-required number of features. \n",
    "# E.g. when num_feats=3, the model will train on all combinations of 3 features from feature_train_list\n",
    "num_feats = 2\n",
    "result_df = pd.DataFrame(columns = ['features','r2_score']) # results of each training will be stored here\n",
    "\n",
    "# iter_tools.combinations provides all combinations of num_feats features\n",
    "for feat_set in itertools.combinations(feat_list, num_feats):\n",
    "\n",
    "    # Convert feature set into list and get string for features used in training\n",
    "    feature_list = list(feat_set)\n",
    "    # flatten feature_list\n",
    "    feature_list = [item for sublist in feature_list for item in sublist]\n",
    "    output_str = get_feat_output(feature_list)\n",
    "\n",
    "    # Split into explanatory and response variables\n",
    "    X = dum_df[feature_list]\n",
    "    y = dum_df['price']\n",
    "\n",
    "    # Split into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state=42)\n",
    "\n",
    "    # Instantiate and fit linear regression model\n",
    "    lm_model = LinearRegression(normalize=True)\n",
    "    lm_model.fit(X_train, y_train) #Fit\n",
    "\n",
    "    # Predict and score the model\n",
    "    y_test_preds = lm_model.predict(X_test)\n",
    "    result_df.loc[len(result_df)] = [output_str[:-1],r2_score(y_test, y_test_preds)]\n",
    "\n",
    "    #result_list.append([output_str[:-1],r2_score(y_test, y_test_preds)])\n",
    "    print(\"For features [{}]: the r-squared score was {} on {} values.\".format(output_str[:-1], r2_score(y_test, y_test_preds), len(y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9042e2b8",
   "metadata": {},
   "source": [
    "# Section 5: Evaluate\n",
    "\n",
    "Question 1: What features of a used car has the greatest affect on its price?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0baf29",
   "metadata": {},
   "source": [
    "We create a heatmap for a correlation matrix, which will show which features correlate most (either positively or negatively) with price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1bc3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap for correlation matrix to study correlation between numerical columns\n",
    "\n",
    "sns.heatmap(df.corr(), annot=True, fmt='.2f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6973537d",
   "metadata": {},
   "source": [
    "Evaluation for Question 1:\n",
    "\n",
    "The strongest positive correlation for price is between price and engine size, so a larger engine size is the best single indicator of a higher price. \n",
    "\n",
    "The strongest negative correlation for price is between price and mileage, and price and age. So older cars, or cars with a higher mileage indicate a lower price when other features are kept constant. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3527d1",
   "metadata": {},
   "source": [
    "Question 2: Is it possible to predict the price of a used car based on existing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79035e0e",
   "metadata": {},
   "source": [
    "Evaluation for Question 2:\n",
    "\n",
    "Setting num_feats = len(feat_list) and running train/test loop, we get:\n",
    "For features [miles_tax_mpg_eng_age_make_model_trans_fuel]: the r-squared score was 0.8693213456408345 on 9919 values. \n",
    "\n",
    "This confirms that the linear-regression model is successfully trained on the training data, and has a good r2 score. We can use exiting data to predict the price of a user car based on all features available. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1993847d",
   "metadata": {},
   "source": [
    "Question 3: Which 3 features of a used car are the best predictor of its price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9969cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting num_feats = 3\n",
    "result_df = result_df.sort_values(by=['r2_score'], ascending=False)\n",
    "\n",
    "# take top 5 and bottom 5 feature combinations by r2_score\n",
    "result_top5 = result_df[:5]\n",
    "result_bottom5 = result_df[-5:]\n",
    "top_bottom_df = pd.concat([result_top5, result_bottom5], axis=0)\n",
    "top_bottom_df.plot.bar(x='features', y='r2_score', rot=0)\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1f042f",
   "metadata": {},
   "source": [
    "Evaluation for Question 3:\n",
    "\n",
    "With an r2 score of 0.826, mileage, engineSize, and model is the best combination for predicting used-car price. \n",
    "With an r2 score of 0.241, mileage, tax, and mpg is the worst combination for predicting price. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
